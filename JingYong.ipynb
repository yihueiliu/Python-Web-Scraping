{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入套件\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, json, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 list 來放置小說連結\n",
    "book_links = []\n",
    "\n",
    "# 標頭，沒有的話有些網站會將你認為是機器人、導致無法讀取\n",
    "# 如何找標頭: 開發人員工具-->Network，重新整理、找第一個出來的物件，裡面最下面有一個user-agent\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def getBooksLinks():\n",
    "    # 金庸小說網站\n",
    "    url = \"https://www.bookwormzz.com/zh/\"\n",
    "\n",
    "    # 用 requests 的 get 方法把網頁抓下來\n",
    "    response = requests.get(url, headers = headers)\n",
    "\n",
    "    # 指定 lxml 作為解析器\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "    books = soup.select('div.epub li a')\n",
    "\n",
    "    for book in books:\n",
    "        #print(book.get_text())\n",
    "        #print(\"https://www.bookwormzz.com/\" + book[\"href\"][3:])\n",
    "        book_links.append({\n",
    "            \"book\": book.get_text(),\n",
    "            \"link\": \"https://www.bookwormzz.com/\" + book[\"href\"][3:]})\n",
    "        \n",
    "chapter_links = []\n",
    "def getChapterLinks():\n",
    "\n",
    "    for index, bookDict in enumerate(book_links):   \n",
    "        #print(\"getChapterLinks:\", bookDict[\"book\"])\n",
    "        res = requests.get(bookDict[\"link\"])\n",
    "        soup_link = BeautifulSoup(res.text, \"lxml\")\n",
    "        #print(\"=\"*30)\n",
    "        \n",
    "        chapters = soup_link.select('#book_toc > div:nth-child(2) > div > ul > li a')\n",
    "        #print(chapters)\n",
    "    \n",
    "        for chapter in chapters:\n",
    "            #print(chapter)\n",
    "            #print(chapter.get_text())\n",
    "            #print(\"https://www.bookwormzz.com/zh\" + chapter[\"href\"])\n",
    "            chapter_links.append({\n",
    "                \"book\": bookDict[\"book\"],\n",
    "                \"chapter_title\": chapter.get_text(),\n",
    "                \"chapter_link\": \"https://www.bookwormzz.com/zh\" + chapter[\"href\"]\n",
    "            })\n",
    "    \n",
    "        #book_links[index][\"chapters\"] = chapter_links\n",
    "    \n",
    "def getChapterContents():\n",
    "    print(\"=\"*60)\n",
    "    for index, chapterDict in enumerate(chapter_links):\n",
    "        print(\"getChapterContents:\", chapterDict[\"book\"], chapterDict[\"chapter_title\"])\n",
    "        res = requests.get(chapterDict[\"chapter_link\"])\n",
    "        soup_link = BeautifulSoup(res.text, \"lxml\")\n",
    "        texts = soup_link.select(\"#html > div:nth-child(1)\")\n",
    "        #print(texts[0].get_text())\n",
    "        contents = re.sub(r\"\\s+\", \"\",texts[0].get_text()) # 去除空白\n",
    "        #print(contents)\n",
    "        chapter_links[index][\"contents\"] = contents\n",
    "\n",
    "# 將所有資訊轉成 JSON 檔\n",
    "def saveJson():\n",
    "    fp = open(\".\\\\JingYong\\\\JingYong.json\", \"w\", encoding = \"utf-8\")\n",
    "    fp.write(json.dumps(chapter_links, ensure_ascii = False))\n",
    "    fp.close()\n",
    "\n",
    "# save to txt\n",
    "def saveTxt():\n",
    "    print(\"=\"*60)\n",
    "    for index, chapterDict in enumerate(chapter_links):\n",
    "        filename = \".\\\\JingYong\\\\\" + chapterDict[\"book\"] + \"_\" + chapterDict[\"chapter_title\"] + \".txt\"\n",
    "        print(\"saveTxt:\", filename)\n",
    "        fp = open(filename, \"w\", encoding = \"utf-8\")\n",
    "        fp.write(chapterDict[\"contents\"])\n",
    "        fp.close()\n",
    "    #print(\"done\")\n",
    "    \n",
    "# 主程式區段\n",
    "if __name__ == \"__main__\":\n",
    "    getBooksLinks()\n",
    "    getChapterLinks()\n",
    "    getChapterContents()\n",
    "    saveJson()\n",
    "    saveTxt()\n",
    "    print(\"---------done----------\")\n",
    "    #print(\"-\"*30)\n",
    "    #print(book_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試，找每本書每章節的連結\n",
    "\n",
    "res = requests.get(book_links[0])\n",
    "soup_link = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "for a in soup_link.select('a'):\n",
    "    if a.has_attr('href'):\n",
    "        print(a.get_text())\n",
    "        print(a['href'])  #或寫 a.get(\"href\") 也可以\n",
    "        print(\"=\" * 50)\n",
    "    else:\n",
    "        print()\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"連結[{a.get_text()}] 沒有 href 屬性\")\n",
    "        print(\"=\" * 50)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
